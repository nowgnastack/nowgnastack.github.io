<!DOCTYPE html>
<html lang=en>
<head>
  <!-- so meta -->
  <meta charset="utf-8" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge" />
  <meta name="HandheldFriendly" content="True" />
  <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=5" />
  <meta name="google-site-verification" content="sdTAxKN3zLoy8rmPlkLzOu030Yo_stjU8dw_ufxbSoA" />
  <meta name="description" content="Outline Pytorch Tutorial  Pytorch란? Pytorch Tudorial Autograd Gradient    Pytorch Tutorial[1&#x2F;4] Pytorch란? pytorch는 파이썬 기반의 오픈소스 머신러닝 라이브러리로, Torch를 기반으로 하고 자연어 처리와 같은 애플리케이션을 위해 사용된다. 페이스북 인공지능 연">
<meta property="og:type" content="article">
<meta property="og:title" content="Pytorch Basics">
<meta property="og:url" content="https://nowgnastack.github.io/2020/08/26/2020-08-26-Reinforcement_Learning2/index.html">
<meta property="og:site_name" content="nowgnastack">
<meta property="og:description" content="Outline Pytorch Tutorial  Pytorch란? Pytorch Tudorial Autograd Gradient    Pytorch Tutorial[1&#x2F;4] Pytorch란? pytorch는 파이썬 기반의 오픈소스 머신러닝 라이브러리로, Torch를 기반으로 하고 자연어 처리와 같은 애플리케이션을 위해 사용된다. 페이스북 인공지능 연">
<meta property="og:locale" content="en_US">
<meta property="og:image" content="https://nowgnastack.github.io/images/img/RL_Study2/jacobian.png">
<meta property="og:image" content="https://nowgnastack.github.io/images/img/RL_Study2/jacobian2.png">
<meta property="article:published_time" content="2020-08-25T15:00:00.000Z">
<meta property="article:modified_time" content="2023-07-23T15:05:34.017Z">
<meta property="article:author" content="nowgnas">
<meta property="article:tag" content="tave">
<meta property="article:tag" content="pytorch">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="https://nowgnastack.github.io/images/img/RL_Study2/jacobian.png">    
  <link rel="shortcut icon" href="/images/favicon.ico" />
     
  <link
    rel="icon"
    type="image/png"
    href="/images/favicon-192x192.png"
    sizes="192x192"
  />
     
  <link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon.png" />
    
  <!-- title -->
  <title>Pytorch Basics</title>
  <!-- async scripts -->
  <!-- Google Analytics -->

  <script async src="https://www.googletagmanager.com/gtag/js?id=G-HS37DQYSPL"></script>
  <script>
      window.dataLayer = window.dataLayer || [];
      function gtag(){dataLayer.push(arguments);}
      gtag('js', new Date());
      gtag('config', 'G-HS37DQYSPL');
  </script>

 <!-- Umami Analytics -->


  <!-- styles -->
  
<link rel="stylesheet" href="/css/style.css">

  <!-- persian styles -->
  
  <!-- rss -->
   
  <!-- mathjax -->
  
  <script type="text/x-mathjax-config">
     MathJax.Hub.Config({
    tex2jax: {
      skipTags: ['script', 'noscript', 'style', 'textarea', 'pre'],
      inlineMath: [['$','$']]
    }
     });
  </script>
  <script
    src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/latest.js?config=TeX-MML-AM_CHTML"
    async
  ></script>
  
  <!--Canonical : 유사하거나 중복된 페이지의 표준 페이지 정의-->
  <link rel="canonical" href="https://nowgnastack.github.io/2020/08/26/2020-08-26-reinforcement_learning2/"/>
<meta name="generator" content="Hexo 6.3.0"><link rel="alternate" href="/atom.xml" title="nowgnastack" type="application/atom+xml">
</head>

<body class="max-width mx-auto px3 ltr">
    
      <div id="header-post">
  <a id="menu-icon" href="#" aria-label="Menu"><i class="fa-solid fa-bars fa-lg"></i></a>
  <a id="menu-icon-tablet" href="#" aria-label="Menu"><i class="fa-solid fa-bars fa-lg"></i></a>
  <a id="top-icon-tablet" href="#" aria-label="Top" onclick="$('html, body').animate({ scrollTop: 0 }, 'fast');" style="display:none;"><i class="fa-solid fa-chevron-up fa-lg"></i></a>
  <span id="menu">
    <span id="nav">
      <ul>
        <!--
       --><li><a href="/">Home</a></li><!--
     --><!--
       --><li><a href="/about/">About</a></li><!--
     --><!--
       --><li><a href="/archives/">Writing</a></li><!--
     --><!--
       --><li><a target="_blank" rel="noopener" href="https://github.com/nowgnas">Projects</a></li><!--
     -->
      </ul>
    </span>
    <br/>
    <span id="actions">
      <ul>
        
        <li><a class="icon" aria-label="Previous post" href="/2020/08/31/2020-08-30-Reinforcement_Learning3/"><i class="fa-solid fa-chevron-left" aria-hidden="true" onmouseover="$('#i-prev').toggle();" onmouseout="$('#i-prev').toggle();"></i></a></li>
        
        
        <li><a class="icon" aria-label="Next post" href="/2020/08/20/2020-08-20-pytorch/"><i class="fa-solid fa-chevron-right" aria-hidden="true" onmouseover="$('#i-next').toggle();" onmouseout="$('#i-next').toggle();"></i></a></li>
        
        <li><a class="icon" aria-label="Back to top" href="#" onclick="$('html, body').animate({ scrollTop: 0 }, 'fast');"><i class="fa-solid fa-chevron-up" aria-hidden="true" onmouseover="$('#i-top').toggle();" onmouseout="$('#i-top').toggle();"></i></a></li>
        <li><a class="icon" aria-label="Share post" href="#"><i class="fa-solid fa-share-alt" aria-hidden="true" onmouseover="$('#i-share').toggle();" onmouseout="$('#i-share').toggle();" onclick="$('#share').toggle();return false;"></i></a></li>
      </ul>
      <span id="i-prev" class="info" style="display:none;">Previous post</span>
      <span id="i-next" class="info" style="display:none;">Next post</span>
      <span id="i-top" class="info" style="display:none;">Back to top</span>
      <span id="i-share" class="info" style="display:none;">Share post</span>
    </span>
    <br/>
    <div id="share" style="display: none">
      <ul>
  <li><a class="icon" target="_blank" rel="noopener" href="http://www.facebook.com/sharer.php?u=https://nowgnastack.github.io/2020/08/26/2020-08-26-Reinforcement_Learning2/"><i class="fab fa-facebook " aria-hidden="true"></i></a></li>
  <li><a class="icon" target="_blank" rel="noopener" href="https://twitter.com/share?url=https://nowgnastack.github.io/2020/08/26/2020-08-26-Reinforcement_Learning2/&text=Pytorch Basics"><i class="fab fa-twitter " aria-hidden="true"></i></a></li>
  <li><a class="icon" target="_blank" rel="noopener" href="http://www.linkedin.com/shareArticle?url=https://nowgnastack.github.io/2020/08/26/2020-08-26-Reinforcement_Learning2/&title=Pytorch Basics"><i class="fab fa-linkedin " aria-hidden="true"></i></a></li>
  <li><a class="icon" target="_blank" rel="noopener" href="https://pinterest.com/pin/create/bookmarklet/?url=https://nowgnastack.github.io/2020/08/26/2020-08-26-Reinforcement_Learning2/&is_video=false&description=Pytorch Basics"><i class="fab fa-pinterest " aria-hidden="true"></i></a></li>
  <li><a class="icon" href="mailto:?subject=Pytorch Basics&body=Check out this article: https://nowgnastack.github.io/2020/08/26/2020-08-26-Reinforcement_Learning2/"><i class="fa-solid fa-envelope " aria-hidden="true"></i></a></li>
  <li><a class="icon" target="_blank" rel="noopener" href="https://getpocket.com/save?url=https://nowgnastack.github.io/2020/08/26/2020-08-26-Reinforcement_Learning2/&title=Pytorch Basics"><i class="fab fa-get-pocket " aria-hidden="true"></i></a></li>
  <li><a class="icon" target="_blank" rel="noopener" href="http://reddit.com/submit?url=https://nowgnastack.github.io/2020/08/26/2020-08-26-Reinforcement_Learning2/&title=Pytorch Basics"><i class="fab fa-reddit " aria-hidden="true"></i></a></li>
  <li><a class="icon" target="_blank" rel="noopener" href="http://www.stumbleupon.com/submit?url=https://nowgnastack.github.io/2020/08/26/2020-08-26-Reinforcement_Learning2/&title=Pytorch Basics"><i class="fab fa-stumbleupon " aria-hidden="true"></i></a></li>
  <li><a class="icon" target="_blank" rel="noopener" href="http://digg.com/submit?url=https://nowgnastack.github.io/2020/08/26/2020-08-26-Reinforcement_Learning2/&title=Pytorch Basics"><i class="fab fa-digg " aria-hidden="true"></i></a></li>
  <li><a class="icon" target="_blank" rel="noopener" href="http://www.tumblr.com/share/link?url=https://nowgnastack.github.io/2020/08/26/2020-08-26-Reinforcement_Learning2/&name=Pytorch Basics&description="><i class="fab fa-tumblr " aria-hidden="true"></i></a></li>
  <li><a class="icon" target="_blank" rel="noopener" href="https://news.ycombinator.com/submitlink?u=https://nowgnastack.github.io/2020/08/26/2020-08-26-Reinforcement_Learning2/&t=Pytorch Basics"><i class="fab fa-hacker-news " aria-hidden="true"></i></a></li>
</ul>

    </div>
    
    
      <div id="toc">
        <ol class="toc"><li class="toc-item toc-level-1"><a class="toc-link" href="#Outline"><span class="toc-number">1.</span> <span class="toc-text">Outline</span></a></li><li class="toc-item toc-level-1"><a class="toc-link" href="#Pytorch-Tutorial"><span class="toc-number">2.</span> <span class="toc-text">Pytorch Tutorial</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#1-4-Pytorch%EB%9E%80"><span class="toc-number">2.1.</span> <span class="toc-text">[1&#x2F;4] Pytorch란?</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#2-4-Pytorch-Tutorial"><span class="toc-number">2.2.</span> <span class="toc-text">[2&#x2F;4] Pytorch Tutorial</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#empty"><span class="toc-number">2.2.1.</span> <span class="toc-text">empty</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#random"><span class="toc-number">2.2.2.</span> <span class="toc-text">random</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#zeros"><span class="toc-number">2.2.3.</span> <span class="toc-text">zeros</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#tensor"><span class="toc-number">2.2.4.</span> <span class="toc-text">tensor</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#new-ones"><span class="toc-number">2.2.5.</span> <span class="toc-text">new ones</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#randn-like"><span class="toc-number">2.2.6.</span> <span class="toc-text">randn_like</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#size"><span class="toc-number">2.2.7.</span> <span class="toc-text">size</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%EB%8D%A7%EC%85%88"><span class="toc-number">2.2.8.</span> <span class="toc-text">덧셈</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#indexing"><span class="toc-number">2.2.9.</span> <span class="toc-text">indexing</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#view"><span class="toc-number">2.2.10.</span> <span class="toc-text">view</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#item"><span class="toc-number">2.2.11.</span> <span class="toc-text">item</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#numpy%EC%99%80%EC%9D%98-%ED%98%B8%ED%99%98%EC%84%B1"><span class="toc-number">2.2.12.</span> <span class="toc-text">numpy와의 호환성</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#3-4-Autograd"><span class="toc-number">2.3.</span> <span class="toc-text">[3&#x2F;4] Autograd</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#requires-grad"><span class="toc-number">2.3.1.</span> <span class="toc-text">requires_grad</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#grad-fn"><span class="toc-number">2.3.2.</span> <span class="toc-text">grad_fn</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#4-4-Gradient"><span class="toc-number">2.4.</span> <span class="toc-text">[4&#x2F;4] Gradient</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#grad"><span class="toc-number">2.4.1.</span> <span class="toc-text">grad</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%EC%95%BC%EC%BD%94%EB%B9%84%EC%95%88-%ED%96%89%EB%A0%AC"><span class="toc-number">2.4.2.</span> <span class="toc-text">야코비안 행렬</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#torch-autograd"><span class="toc-number">2.4.3.</span> <span class="toc-text">torch.autograd</span></a></li></ol></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link" href="#%EC%A0%95%EB%A6%AC"><span class="toc-number">3.</span> <span class="toc-text">정리</span></a></li></ol>
      </div>
    
  </span>
</div>

    
    <div class="content index py4 ">
        
        <article class="post h-entry" itemscope itemtype="http://schema.org/BlogPosting">
  <header>
    
    <h1 class="posttitle p-name" itemprop="name headline">
        Pytorch Basics
    </h1>



    <div class="meta">
      <span class="author p-author h-card" itemprop="author" itemscope itemtype="http://schema.org/Person">
        <span class="p-name" itemprop="name">nowgnas</span>
      </span>
      
    <div class="postdate">
      
        <time datetime="2020-08-25T15:00:00.000Z" class="dt-published" itemprop="datePublished">2020-08-26</time>
        
      
    </div>


      
<div class="article-category">
  <i class="fa-solid fa-archive"></i>
  <a class="category-link" href="/categories/deep-learning/">deep learning</a>
</div>


      
    <div class="article-tag">
        <i class="fa-solid fa-tag"></i>
        <a class="p-category" href="/tags/pytorch/" rel="tag">pytorch</a>, <a class="p-category" href="/tags/tave/" rel="tag">tave</a>
    </div>


    </div>
  </header>
  

  <div class="content e-content" itemprop="articleBody">
    <h1 id="Outline"><a href="#Outline" class="headerlink" title="Outline"></a>Outline</h1><ol>
<li><p>Pytorch Tutorial</p>
<ul>
<li>Pytorch란?</li>
<li>Pytorch Tudorial</li>
<li>Autograd</li>
<li>Gradient</li>
</ul>
</li>
</ol>
<h1 id="Pytorch-Tutorial"><a href="#Pytorch-Tutorial" class="headerlink" title="Pytorch Tutorial"></a>Pytorch Tutorial</h1><h2 id="1-4-Pytorch란"><a href="#1-4-Pytorch란" class="headerlink" title="[1&#x2F;4] Pytorch란?"></a>[1&#x2F;4] Pytorch란?</h2><ul>
<li>pytorch는 파이썬 기반의 오픈소스 머신러닝 라이브러리로, Torch를 기반으로 하고 자연어 처리와 같은 애플리케이션을 위해 사용된다. 페이스북 인공지능 연구집단에 의해 개발되었다. 간결하고 구현이 빠르며 텐서플로우보다 익히기 쉽다.</li>
</ul>
<h2 id="2-4-Pytorch-Tutorial"><a href="#2-4-Pytorch-Tutorial" class="headerlink" title="[2&#x2F;4] Pytorch Tutorial"></a>[2&#x2F;4] Pytorch Tutorial</h2><h3 id="empty"><a href="#empty" class="headerlink" title="empty"></a>empty</h3><ul>
<li>tensor는 자료형의 단위이다.</li>
<li>torch.empty는 초기화 되지 않은 행렬으로, 그 시점에 할당된 메모리에 존재하던 값이 초기값으로 나타난다.</li>
<li>type(x)를 출력해보면 자료형이 torch.tensor라고 나온다.</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"></span><br><span class="line">x = torch.empty(<span class="number">5</span>, <span class="number">3</span>)</span><br><span class="line"><span class="built_in">print</span>(x)</span><br><span class="line"><span class="built_in">print</span>(<span class="built_in">type</span>(x))</span><br></pre></td></tr></table></figure>

<figure class="highlight html"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">out: tensor([[4.8689e-36, 0.0000e+00, 5.6052e-45], [ 0.0000e+00, 1.4013e-45, 0.0000e+00], [</span><br><span class="line">1.4013e-45, 0.0000e+00, -2.0294e+00], [-3.0359e-01, -6.3788e-01, 1.1869e-01], [-2.8520e-01,</span><br><span class="line">-6.8363e-01, -4.3497e-01]]) <span class="tag">&lt;<span class="name">class</span> &#x27;<span class="attr">torch.Tensor</span>&#x27;&gt;</span></span><br></pre></td></tr></table></figure>

<h3 id="random"><a href="#random" class="headerlink" title="random"></a>random</h3><ul>
<li>rand 는 0,1 사이에 균등분포에서 랜덤으로 값을 가져와 행렬을 만든다</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">x = torch.rand(<span class="number">5</span>, <span class="number">3</span>)</span><br><span class="line"><span class="built_in">print</span>(x)</span><br></pre></td></tr></table></figure>

<figure class="highlight html"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">tensor([[0.7194, 0.6460, 0.8726], [0.3167, 0.1146, 0.4650], [0.5900, 0.7723, 0.1102], [0.3511,</span><br><span class="line">0.8640, 0.3159], [0.3506, 0.8203, 0.9907]])</span><br></pre></td></tr></table></figure>

<h3 id="zeros"><a href="#zeros" class="headerlink" title="zeros"></a>zeros</h3><ul>
<li>0 으로 채워진 행렬을 생성</li>
<li>dtype은 자료형을 지정할 수 있다. (ex. torch.long, torch.int …)</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">x = torch.zeros(<span class="number">5</span>, <span class="number">3</span>, dtype=torch.long)</span><br><span class="line"><span class="built_in">print</span>(x)</span><br></pre></td></tr></table></figure>

<figure class="highlight html"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">tensor([[0, 0, 0], [0, 0, 0], [0, 0, 0], [0, 0, 0], [0, 0, 0]])</span><br></pre></td></tr></table></figure>

<h3 id="tensor"><a href="#tensor" class="headerlink" title="tensor"></a>tensor</h3><ul>
<li>데이터를 넣어서 텐서를 생성할 수도 있다.</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">x = torch.tensor([<span class="number">5.5</span>, <span class="number">3</span>])</span><br><span class="line"><span class="built_in">print</span>(x)</span><br></pre></td></tr></table></figure>

<figure class="highlight html"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">tensor([5.5000, 3.0000])</span><br></pre></td></tr></table></figure>

<h3 id="new-ones"><a href="#new-ones" class="headerlink" title="new ones"></a>new ones</h3><ul>
<li>new_* 메소드는 크기를 받는다.</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">x = x.new_ones(<span class="number">5</span>, <span class="number">3</span>, dtype=torch.double)</span><br><span class="line"><span class="built_in">print</span>(x)</span><br></pre></td></tr></table></figure>

<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">tensor([[<span class="number">1.</span>, <span class="number">1.</span>, <span class="number">1.</span>],</span><br><span class="line">[<span class="number">1.</span>, <span class="number">1.</span>, <span class="number">1.</span>],</span><br><span class="line">[<span class="number">1.</span>, <span class="number">1.</span>, <span class="number">1.</span>],</span><br><span class="line">[<span class="number">1.</span>, <span class="number">1.</span>, <span class="number">1.</span>],</span><br><span class="line">[<span class="number">1.</span>, <span class="number">1.</span>, <span class="number">1.</span>]], dtype=torch.float64)</span><br></pre></td></tr></table></figure>

<h3 id="randn-like"><a href="#randn-like" class="headerlink" title="randn_like"></a>randn_like</h3><ul>
<li>dtype을 오버라이드한다.</li>
<li>randn_like는 사이즈를 튜플로 입력하지 않고 기존의 텐서로 정의한다.</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">x = torch.randn_like(x, dtype=torch.<span class="built_in">float</span>)</span><br><span class="line"><span class="built_in">print</span>(x)</span><br></pre></td></tr></table></figure>

<figure class="highlight html"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">tensor([[-1.6818, 1.0321, -0.8268], [ 0.5849, 0.2614, -1.0141], [-1.3403, 0.0985, -2.0294],</span><br><span class="line">[-0.3036, -0.6379, 0.1187], [-0.2852, -0.6836, -0.4350]])</span><br></pre></td></tr></table></figure>

<h3 id="size"><a href="#size" class="headerlink" title="size"></a>size</h3><ul>
<li>x.size()는 x의 크기를 알 수 있다.</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">print</span>(x.size())</span><br></pre></td></tr></table></figure>

<figure class="highlight html"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">torch.Size([5, 3])</span><br></pre></td></tr></table></figure>

<h3 id="덧셈"><a href="#덧셈" class="headerlink" title="덧셈"></a>덧셈</h3><ul>
<li>torch에서의 덧셈연산이다.</li>
<li>+ 연산자와 torch.add()로 연산이 가능하다.</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">y = torch.rand(<span class="number">5</span>, <span class="number">3</span>)</span><br><span class="line"><span class="built_in">print</span>(x + y)</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(torch.add(x, y))</span><br></pre></td></tr></table></figure>

<figure class="highlight html"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">tensor([[1.1330, 1.1318, -0.0505], [ 1.3939, 1.1446, 1.4834], [ 0.0519, -0.4940, 0.8106], [ 1.4957,</span><br><span class="line">1.4173, 2.0778], [-0.7459, 0.8813, -0.7525]]) tensor([[1.1330, 1.1318, -0.0505], [ 1.3939, 1.1446,</span><br><span class="line">1.4834], [ 0.0519, -0.4940, 0.8106], [ 1.4957, 1.4173, 2.0778], [-0.7459, 0.8813, -0.7525]])</span><br></pre></td></tr></table></figure>

<ul>
<li>아래와 같은 방식도 가능하다.</li>
<li>결과를 빈 tensor에 넣어 출력을 한다.</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">result = torch.empty(<span class="number">5</span>, <span class="number">3</span>)</span><br><span class="line">torch.add(x, y, out=result)</span><br><span class="line"><span class="built_in">print</span>(result)</span><br></pre></td></tr></table></figure>

<figure class="highlight html"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">tensor([[1.1330, 1.1318, -0.0505], [ 1.3939, 1.1446, 1.4834], [ 0.0519, -0.4940, 0.8106], [ 1.4957,</span><br><span class="line">1.4173, 2.0778], [-0.7459, 0.8813, -0.7525]])</span><br></pre></td></tr></table></figure>

<ul>
<li>in place 방식이며, 바꿔치기 방식이라고 한다.</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line"><span class="comment"># y에 x 더하기</span></span><br><span class="line"></span><br><span class="line">y.add\_(x)</span><br><span class="line"><span class="built_in">print</span>(y)</span><br></pre></td></tr></table></figure>

<figure class="highlight html"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">tensor([[1.1330, 1.1318, -0.0505], [ 1.3939, 1.1446, 1.4834], [ 0.0519, -0.4940, 0.8106], [ 1.4957,</span><br><span class="line">1.4173, 2.0778], [-0.7459, 0.8813, -0.7525]])</span><br></pre></td></tr></table></figure>

<h3 id="indexing"><a href="#indexing" class="headerlink" title="indexing"></a>indexing</h3><ul>
<li>아래와 같은 indexing은 전체 행에서 1번째 열만 가져오는 코드이다.</li>
<li>x tensor를 같이 출력해보면 1번째 열만 출력된 것을 볼 수 있다.</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">print</span>(x)</span><br><span class="line"><span class="built_in">print</span>(x[:, <span class="number">1</span>])</span><br></pre></td></tr></table></figure>

<figure class="highlight html"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">tensor([[0.3303, 0.9045, -0.1993], [ 0.5441, 0.5543, 0.9550], [-0.4737, -0.6022, 0.5375], [ 1.3710,</span><br><span class="line">0.9057, 1.3939], [-0.9738, 0.0332, -1.4871]]) tensor([ 0.9045, 0.5543, -0.6022, 0.9057, 0.0332])</span><br></pre></td></tr></table></figure>

<h3 id="view"><a href="#view" class="headerlink" title="view"></a>view</h3><ul>
<li>torch.view는 tensor의 크기와 모양을 변경해 준다.</li>
<li>4x4로 선언된 x tensor를 view를 사용해 크기를 변경해 주었다.</li>
<li>view에서 -1은 자동으로 모양을 채워준다.</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">x = torch.randn(<span class="number">4</span>, <span class="number">4</span>)</span><br><span class="line">y = x.view(<span class="number">16</span>)</span><br><span class="line">z = x.view(-<span class="number">1</span>, <span class="number">8</span>)</span><br><span class="line"><span class="built_in">print</span>(x.size(), y.size(), z.size())</span><br></pre></td></tr></table></figure>

<figure class="highlight html"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">torch.Size([4, 4]) torch.Size([16]) torch.Size([2, 8])</span><br></pre></td></tr></table></figure>

<h3 id="item"><a href="#item" class="headerlink" title="item"></a>item</h3><ul>
<li>tensor의 내부 값만 가져온다.</li>
<li>int형으로 반환해 준다.</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">x = torch.randn(<span class="number">1</span>)</span><br><span class="line"><span class="built_in">print</span>(x)</span><br><span class="line"><span class="built_in">print</span>(x.item())</span><br></pre></td></tr></table></figure>

<figure class="highlight html"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">tensor([-1.8750]) -1.874952793121338</span><br></pre></td></tr></table></figure>

<h3 id="numpy와의-호환성"><a href="#numpy와의-호환성" class="headerlink" title="numpy와의 호환성"></a>numpy와의 호환성</h3><ul>
<li>numpy와 형변환이 매우 편리하다.</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line">a = np.ones(<span class="number">5</span>)</span><br><span class="line">b = torch.from_numpy(a)</span><br><span class="line">np.add(a, <span class="number">1</span>, out=a)</span><br><span class="line"><span class="built_in">print</span>(a)</span><br><span class="line"><span class="built_in">print</span>(b)</span><br></pre></td></tr></table></figure>

<figure class="highlight html"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[2. 2. 2. 2. 2.] tensor([2., 2., 2., 2., 2.], dtype=torch.float64)</span><br></pre></td></tr></table></figure>

<h2 id="3-4-Autograd"><a href="#3-4-Autograd" class="headerlink" title="[3&#x2F;4] Autograd"></a>[3&#x2F;4] Autograd</h2><h3 id="requires-grad"><a href="#requires-grad" class="headerlink" title="requires_grad"></a>requires_grad</h3><ul>
<li>requires_grad의 속성을 True로 하면, 해당 tensor에서 이뤄진 모든 연산을 추적하기 시작한다.</li>
<li>requires_grad 는 기존의 값을 바꿔치기 하여 tensor 를 변경한다.</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">x = torch.ones(<span class="number">2</span>, <span class="number">2</span>, requires_grad=<span class="literal">True</span>)</span><br><span class="line"><span class="built_in">print</span>(x)</span><br></pre></td></tr></table></figure>

<figure class="highlight html"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">tensor([[1., 1.], [1., 1.]], requires_grad=True)</span><br></pre></td></tr></table></figure>

<ul>
<li>requires_grad의 속성을 명시하지 않으면 기본적으로 True가 된다.</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">a = torch.randn(<span class="number">2</span>, <span class="number">2</span>)</span><br><span class="line">a = ((a _ <span class="number">8</span>) / (a - <span class="number">2</span>))</span><br><span class="line"><span class="built_in">print</span>(a.requires*grad)</span><br><span class="line">a.requires_grad*(<span class="literal">True</span>)</span><br><span class="line"><span class="built_in">print</span>(a.requires_grad)</span><br><span class="line">b = (a _ a).<span class="built_in">sum</span>()</span><br><span class="line"><span class="built_in">print</span>(b.grad_fn)</span><br></pre></td></tr></table></figure>

<figure class="highlight html"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">False True <span class="tag">&lt;<span class="name">SumBackward0</span> <span class="attr">object</span> <span class="attr">at</span> <span class="attr">0x7effda51c518</span>&gt;</span><span class="tag">&lt;/<span class="name">SumBackward0</span>&gt;</span></span><br></pre></td></tr></table></figure>

<h3 id="grad-fn"><a href="#grad-fn" class="headerlink" title="grad_fn"></a>grad_fn</h3><ul>
<li>grad_fn은 연산의 결과로 생성된 것이라는 표시이다.</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">y = x + <span class="number">2</span></span><br><span class="line"><span class="built_in">print</span>(y)</span><br></pre></td></tr></table></figure>

<figure class="highlight html"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">tensor([[3., 3.], [3., 3.]], grad_fn=<span class="tag">&lt;<span class="name">AddBackward0</span>&gt;</span>)<span class="tag">&lt;/<span class="name">AddBackward0</span>&gt;</span></span><br></pre></td></tr></table></figure>

<ul>
<li>추가로 연산을 수행하였다.</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">z = y _ y _ <span class="number">3</span></span><br><span class="line">out = z.mean()</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(z, out)</span><br></pre></td></tr></table></figure>

<figure class="highlight html"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">tensor([[27., 27.], [27., 27.]], grad_fn=<span class="tag">&lt;<span class="name">MulBackward0</span></span></span><br><span class="line"><span class="tag">  &gt;</span>) tensor(27., grad_fn=<span class="tag">&lt;<span class="name">MeanBackward0</span>&gt;</span>)<span class="tag">&lt;/<span class="name">MeanBackward0</span>&gt;</span>&lt;/MulBackward0</span><br><span class="line">&gt;</span><br></pre></td></tr></table></figure>

<h2 id="4-4-Gradient"><a href="#4-4-Gradient" class="headerlink" title="[4&#x2F;4] Gradient"></a>[4&#x2F;4] Gradient</h2><h3 id="grad"><a href="#grad" class="headerlink" title="grad"></a>grad</h3><ul>
<li>out은 위의 z.mean()의 값과 같다.</li>
<li>grad를 이용해 변화도를 출력한다.</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">out.backward()</span><br><span class="line"><span class="built_in">print</span>(x.grad)</span><br></pre></td></tr></table></figure>

<figure class="highlight html"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">tensor([[4.5000, 4.5000], [4.5000, 4.5000]])</span><br></pre></td></tr></table></figure>

<h3 id="야코비안-행렬"><a href="#야코비안-행렬" class="headerlink" title="야코비안 행렬"></a>야코비안 행렬</h3><ul>
<li>gradient는 스칼라 함수에 대한 일차 미분이지만, 야코비안 행렬은 다변수 벡터 함수에 대한 일차 미분이다.</li>
<li>아래 식은 야코비안 행렬을 정의한 것이다.<br><img src="/images/img/RL_Study2/jacobian.png" alt="jacobian"></li>
</ul>
<h3 id="torch-autograd"><a href="#torch-autograd" class="headerlink" title="torch.autograd"></a>torch.autograd</h3><ul>
<li>torch.autograd는 벡터-야코비안 곱을 계산한다.</li>
<li>벡터 v &#x3D; (v<sub>1</sub> v<sub>2</sub> … v<sub>m</sub>)<sup>T</sup>에 대해 v<sup>T</sup> * J을 연산한다.<br><img src="/images/img/RL_Study2/jacobian2.png" alt="jacobian2"></li>
</ul>
<h1 id="정리"><a href="#정리" class="headerlink" title="정리"></a>정리</h1><blockquote>
<p>tensorflow와 pytorch 둘다 접해보았지만 확실히 pytorch가 조금 더 이해가 빠르고 numpy와 형변환도 자유로워 좋은것 같다.</p>
</blockquote>
<blockquote>
<p>지금 보고있는 유튜브 강의(<a target="_blank" rel="noopener" href="https://www.youtube.com/playlist?list=PLQ28Nx3M4JrhkqBVIXg-i5_CVVoS1UzAv">모두를 위한 딥러닝2 pytorch</a>)가 pytorch로 딥러닝을 시작하기에 좋은 강의인것 같다. 김성훈 교수님의 <a target="_blank" rel="noopener" href="https://www.youtube.com/playlist?list=PLlMkM4tgfjnLSOjrEJN31gZATbcj_MpUm">모두를 위한 딥러닝1 tensorflow</a>도 잘 가르쳐 주셔서 재미있게 들을 수 있다.</p>
</blockquote>

  </div>
</article>


    <div class="blog-post-comments">
        <div id="utterances_thread">
            <noscript>Please enable JavaScript to view the comments.</noscript>
        </div>
    </div>


        
          <div id="footer-post-container">
  <div id="footer-post">

    <div id="nav-footer" style="display: none">
      <ul>
        
          <li><a href="/">Home</a></li>
        
          <li><a href="/about/">About</a></li>
        
          <li><a href="/archives/">Writing</a></li>
        
          <li><a target="_blank" rel="noopener" href="https://github.com/nowgnas">Projects</a></li>
        
      </ul>
    </div>

    
    
      <div id="toc-footer" style="display: none">
        <ol class="toc"><li class="toc-item toc-level-1"><a class="toc-link" href="#Outline"><span class="toc-number">1.</span> <span class="toc-text">Outline</span></a></li><li class="toc-item toc-level-1"><a class="toc-link" href="#Pytorch-Tutorial"><span class="toc-number">2.</span> <span class="toc-text">Pytorch Tutorial</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#1-4-Pytorch%EB%9E%80"><span class="toc-number">2.1.</span> <span class="toc-text">[1&#x2F;4] Pytorch란?</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#2-4-Pytorch-Tutorial"><span class="toc-number">2.2.</span> <span class="toc-text">[2&#x2F;4] Pytorch Tutorial</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#empty"><span class="toc-number">2.2.1.</span> <span class="toc-text">empty</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#random"><span class="toc-number">2.2.2.</span> <span class="toc-text">random</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#zeros"><span class="toc-number">2.2.3.</span> <span class="toc-text">zeros</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#tensor"><span class="toc-number">2.2.4.</span> <span class="toc-text">tensor</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#new-ones"><span class="toc-number">2.2.5.</span> <span class="toc-text">new ones</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#randn-like"><span class="toc-number">2.2.6.</span> <span class="toc-text">randn_like</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#size"><span class="toc-number">2.2.7.</span> <span class="toc-text">size</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%EB%8D%A7%EC%85%88"><span class="toc-number">2.2.8.</span> <span class="toc-text">덧셈</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#indexing"><span class="toc-number">2.2.9.</span> <span class="toc-text">indexing</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#view"><span class="toc-number">2.2.10.</span> <span class="toc-text">view</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#item"><span class="toc-number">2.2.11.</span> <span class="toc-text">item</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#numpy%EC%99%80%EC%9D%98-%ED%98%B8%ED%99%98%EC%84%B1"><span class="toc-number">2.2.12.</span> <span class="toc-text">numpy와의 호환성</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#3-4-Autograd"><span class="toc-number">2.3.</span> <span class="toc-text">[3&#x2F;4] Autograd</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#requires-grad"><span class="toc-number">2.3.1.</span> <span class="toc-text">requires_grad</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#grad-fn"><span class="toc-number">2.3.2.</span> <span class="toc-text">grad_fn</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#4-4-Gradient"><span class="toc-number">2.4.</span> <span class="toc-text">[4&#x2F;4] Gradient</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#grad"><span class="toc-number">2.4.1.</span> <span class="toc-text">grad</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%EC%95%BC%EC%BD%94%EB%B9%84%EC%95%88-%ED%96%89%EB%A0%AC"><span class="toc-number">2.4.2.</span> <span class="toc-text">야코비안 행렬</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#torch-autograd"><span class="toc-number">2.4.3.</span> <span class="toc-text">torch.autograd</span></a></li></ol></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link" href="#%EC%A0%95%EB%A6%AC"><span class="toc-number">3.</span> <span class="toc-text">정리</span></a></li></ol>
      </div>
    

    <div id="share-footer" style="display: none">
      <ul>
  <li><a class="icon" target="_blank" rel="noopener" href="http://www.facebook.com/sharer.php?u=https://nowgnastack.github.io/2020/08/26/2020-08-26-Reinforcement_Learning2/"><i class="fab fa-facebook fa-lg" aria-hidden="true"></i></a></li>
  <li><a class="icon" target="_blank" rel="noopener" href="https://twitter.com/share?url=https://nowgnastack.github.io/2020/08/26/2020-08-26-Reinforcement_Learning2/&text=Pytorch Basics"><i class="fab fa-twitter fa-lg" aria-hidden="true"></i></a></li>
  <li><a class="icon" target="_blank" rel="noopener" href="http://www.linkedin.com/shareArticle?url=https://nowgnastack.github.io/2020/08/26/2020-08-26-Reinforcement_Learning2/&title=Pytorch Basics"><i class="fab fa-linkedin fa-lg" aria-hidden="true"></i></a></li>
  <li><a class="icon" target="_blank" rel="noopener" href="https://pinterest.com/pin/create/bookmarklet/?url=https://nowgnastack.github.io/2020/08/26/2020-08-26-Reinforcement_Learning2/&is_video=false&description=Pytorch Basics"><i class="fab fa-pinterest fa-lg" aria-hidden="true"></i></a></li>
  <li><a class="icon" href="mailto:?subject=Pytorch Basics&body=Check out this article: https://nowgnastack.github.io/2020/08/26/2020-08-26-Reinforcement_Learning2/"><i class="fa-solid fa-envelope fa-lg" aria-hidden="true"></i></a></li>
  <li><a class="icon" target="_blank" rel="noopener" href="https://getpocket.com/save?url=https://nowgnastack.github.io/2020/08/26/2020-08-26-Reinforcement_Learning2/&title=Pytorch Basics"><i class="fab fa-get-pocket fa-lg" aria-hidden="true"></i></a></li>
  <li><a class="icon" target="_blank" rel="noopener" href="http://reddit.com/submit?url=https://nowgnastack.github.io/2020/08/26/2020-08-26-Reinforcement_Learning2/&title=Pytorch Basics"><i class="fab fa-reddit fa-lg" aria-hidden="true"></i></a></li>
  <li><a class="icon" target="_blank" rel="noopener" href="http://www.stumbleupon.com/submit?url=https://nowgnastack.github.io/2020/08/26/2020-08-26-Reinforcement_Learning2/&title=Pytorch Basics"><i class="fab fa-stumbleupon fa-lg" aria-hidden="true"></i></a></li>
  <li><a class="icon" target="_blank" rel="noopener" href="http://digg.com/submit?url=https://nowgnastack.github.io/2020/08/26/2020-08-26-Reinforcement_Learning2/&title=Pytorch Basics"><i class="fab fa-digg fa-lg" aria-hidden="true"></i></a></li>
  <li><a class="icon" target="_blank" rel="noopener" href="http://www.tumblr.com/share/link?url=https://nowgnastack.github.io/2020/08/26/2020-08-26-Reinforcement_Learning2/&name=Pytorch Basics&description="><i class="fab fa-tumblr fa-lg" aria-hidden="true"></i></a></li>
  <li><a class="icon" target="_blank" rel="noopener" href="https://news.ycombinator.com/submitlink?u=https://nowgnastack.github.io/2020/08/26/2020-08-26-Reinforcement_Learning2/&t=Pytorch Basics"><i class="fab fa-hacker-news fa-lg" aria-hidden="true"></i></a></li>
</ul>

    </div>

    <div id="actions-footer">
        <a id="menu" class="icon" href="#" onclick="$('#nav-footer').toggle();return false;"><i class="fa-solid fa-bars fa-lg" aria-hidden="true"></i> Menu</a>
        
          <a id="toc" class="icon" href="#" onclick="$('#toc-footer').toggle();return false;"><i class="fa-solid fa-list fa-lg" aria-hidden="true"></i> TOC</a>
        
        <a id="share" class="icon" href="#" onclick="$('#share-footer').toggle();return false;"><i class="fa-solid fa-share-alt fa-lg" aria-hidden="true"></i> Share</a>
        <a id="top" style="display:none" class="icon" href="#" onclick="$('html, body').animate({ scrollTop: 0 }, 'fast');"><i class="fa-solid fa-chevron-up fa-lg" aria-hidden="true"></i> Top</a>
    </div>

  </div>
</div>

        
        <footer id="footer">
  <div class="footer-left">
    Copyright &copy;
    
    
    2020-2023
    nowgnas
  </div>
  <div class="footer-right">
    <nav>
      <ul>
        <!--
       --><li><a href="/">Home</a></li><!--
     --><!--
       --><li><a href="/about/">About</a></li><!--
     --><!--
       --><li><a href="/archives/">Writing</a></li><!--
     --><!--
       --><li><a target="_blank" rel="noopener" href="https://github.com/nowgnas">Projects</a></li><!--
     -->
      </ul>
    </nav>
  </div>
</footer>

    </div>
    <!-- styles -->



  <link rel="preload" as="style" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.4.0/css/all.min.css" crossorigin="anonymous" onload="this.onload=null;this.rel='stylesheet'"/>


    <!-- jquery -->

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.6.0/jquery.min.js" crossorigin="anonymous"></script>




<!-- clipboard -->

  
    <script src="https://cdnjs.cloudflare.com/ajax/libs/clipboard.js/2.0.7/clipboard.min.js" crossorigin="anonymous"></script>
  
  <script type="text/javascript">
  $(function() {
    // copy-btn HTML
    var btn = "<span class=\"btn-copy tooltipped tooltipped-sw\" aria-label=\"Copy to clipboard!\">";
    btn += '<i class="fa-regular fa-clone"></i>';
    btn += '</span>';
    // mount it!
    $(".highlight table").before(btn);
    var clip = new ClipboardJS('.btn-copy', {
      text: function(trigger) {
        return Array.from(trigger.nextElementSibling.querySelectorAll('.code')).reduce((str,it)=>str+it.innerText+'\n','')
      }
    });
    clip.on('success', function(e) {
      e.trigger.setAttribute('aria-label', "Copied!");
      e.clearSelection();
    })
  })
  </script>


<script src="/js/main.js"></script>

<!-- search -->

<!-- Baidu Analytics -->

<!-- Cloudflare Analytics -->

<!-- Disqus Comments -->

<!-- utterances Comments -->

    <script type="text/javascript">
      var utterances_repo = 'nowgnastack/nowgnastack.github.io';
      var utterances_issue_term = 'pathname';
      var utterances_label = 'Comment';
      var utterances_theme = 'github-light';

      (function(){
          var script = document.createElement('script');

          script.src = 'https://utteranc.es/client.js';
          script.setAttribute('repo', utterances_repo);
          script.setAttribute('issue-term', 'pathname');
          script.setAttribute('label', utterances_label);
          script.setAttribute('theme', utterances_theme);
          script.setAttribute('crossorigin', 'anonymous');
          script.async = true;
          (document.getElementById('utterances_thread')).appendChild(script);
      }());
  </script>

</body>
</html>
