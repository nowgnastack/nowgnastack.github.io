<!DOCTYPE html>
<html lang=en>
<head>
  <!-- so meta -->
  <meta charset="utf-8" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge" />
  <meta name="HandheldFriendly" content="True" />
  <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=5" />
  <meta name="google-site-verification" content="sdTAxKN3zLoy8rmPlkLzOu030Yo_stjU8dw_ufxbSoA" />
  <meta name="description" content="Loss Function 신경망에서는 하나의 지표를 기준으로 최적의 매개변수 값을 탐색한다. 신경망 학습에서 사용하는 지표는 손실 함수(loss function)이다.  SSE(sum of squares for error)\begin{align}E &#x3D; {1&#x2F;2} {\sum}_k{(y_k - t_k)^2}\end{align}  $y_k$는">
<meta property="og:type" content="article">
<meta property="og:title" content="Neural Network III">
<meta property="og:url" content="https://nowgnastack.github.io/2021/01/03/2021-01-03-TAVE_Research3/index.html">
<meta property="og:site_name" content="nowgnastack">
<meta property="og:description" content="Loss Function 신경망에서는 하나의 지표를 기준으로 최적의 매개변수 값을 탐색한다. 신경망 학습에서 사용하는 지표는 손실 함수(loss function)이다.  SSE(sum of squares for error)\begin{align}E &#x3D; {1&#x2F;2} {\sum}_k{(y_k - t_k)^2}\end{align}  $y_k$는">
<meta property="og:locale" content="en_US">
<meta property="og:image" content="https://nowgnastack.github.io/images/img/posts/TaveResearch/neuralN3/log.png">
<meta property="og:image" content="https://nowgnastack.github.io/images/img/posts/TaveResearch/neuralN3/loss_acc.png">
<meta property="article:published_time" content="2021-01-02T15:00:00.000Z">
<meta property="article:modified_time" content="2023-07-23T15:06:45.335Z">
<meta property="article:author" content="nowgnas">
<meta property="article:tag" content="deep learning">
<meta property="article:tag" content="tave">
<meta property="article:tag" content="tave research">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="https://nowgnastack.github.io/images/img/posts/TaveResearch/neuralN3/log.png">    
  <link rel="shortcut icon" href="/images/favicon.ico" />
     
  <link
    rel="icon"
    type="image/png"
    href="/images/favicon-192x192.png"
    sizes="192x192"
  />
     
  <link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon.png" />
    
  <!-- title -->
  <title>Neural Network III</title>
  <!-- async scripts -->
  <!-- Google Analytics -->

  <script async src="https://www.googletagmanager.com/gtag/js?id=G-HS37DQYSPL"></script>
  <script>
      window.dataLayer = window.dataLayer || [];
      function gtag(){dataLayer.push(arguments);}
      gtag('js', new Date());
      gtag('config', 'G-HS37DQYSPL');
  </script>

 <!-- Umami Analytics -->


  <!-- styles -->
  
<link rel="stylesheet" href="/css/style.css">

  <!-- persian styles -->
  
  <!-- rss -->
   
  <!-- mathjax -->
  
  <script type="text/x-mathjax-config">
     MathJax.Hub.Config({
    tex2jax: {
      skipTags: ['script', 'noscript', 'style', 'textarea', 'pre'],
      inlineMath: [['$','$']]
    }
     });
  </script>
  <script
    src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/latest.js?config=TeX-MML-AM_CHTML"
    async
  ></script>
  
  <!--Canonical : 유사하거나 중복된 페이지의 표준 페이지 정의-->
  <link rel="canonical" href="https://nowgnastack.github.io/2021/01/03/2021-01-03-tave_research3/"/>
<meta name="generator" content="Hexo 6.3.0"><link rel="alternate" href="/atom.xml" title="nowgnastack" type="application/atom+xml">
</head>

<body class="max-width mx-auto px3 ltr">
    
      <div id="header-post">
  <a id="menu-icon" href="#" aria-label="Menu"><i class="fa-solid fa-bars fa-lg"></i></a>
  <a id="menu-icon-tablet" href="#" aria-label="Menu"><i class="fa-solid fa-bars fa-lg"></i></a>
  <a id="top-icon-tablet" href="#" aria-label="Top" onclick="$('html, body').animate({ scrollTop: 0 }, 'fast');" style="display:none;"><i class="fa-solid fa-chevron-up fa-lg"></i></a>
  <span id="menu">
    <span id="nav">
      <ul>
        <!--
       --><li><a href="/">Home</a></li><!--
     --><!--
       --><li><a href="/about/">About</a></li><!--
     --><!--
       --><li><a href="/archives/">Writing</a></li><!--
     --><!--
       --><li><a target="_blank" rel="noopener" href="https://github.com/nowgnas">Projects</a></li><!--
     -->
      </ul>
    </span>
    <br/>
    <span id="actions">
      <ul>
        
        <li><a class="icon" aria-label="Previous post" href="/2021/01/09/2021-01-09-TAVE_Research4/"><i class="fa-solid fa-chevron-left" aria-hidden="true" onmouseover="$('#i-prev').toggle();" onmouseout="$('#i-prev').toggle();"></i></a></li>
        
        
        <li><a class="icon" aria-label="Next post" href="/2021/01/02/2021-01-02-TAVE_Research2/"><i class="fa-solid fa-chevron-right" aria-hidden="true" onmouseover="$('#i-next').toggle();" onmouseout="$('#i-next').toggle();"></i></a></li>
        
        <li><a class="icon" aria-label="Back to top" href="#" onclick="$('html, body').animate({ scrollTop: 0 }, 'fast');"><i class="fa-solid fa-chevron-up" aria-hidden="true" onmouseover="$('#i-top').toggle();" onmouseout="$('#i-top').toggle();"></i></a></li>
        <li><a class="icon" aria-label="Share post" href="#"><i class="fa-solid fa-share-alt" aria-hidden="true" onmouseover="$('#i-share').toggle();" onmouseout="$('#i-share').toggle();" onclick="$('#share').toggle();return false;"></i></a></li>
      </ul>
      <span id="i-prev" class="info" style="display:none;">Previous post</span>
      <span id="i-next" class="info" style="display:none;">Next post</span>
      <span id="i-top" class="info" style="display:none;">Back to top</span>
      <span id="i-share" class="info" style="display:none;">Share post</span>
    </span>
    <br/>
    <div id="share" style="display: none">
      <ul>
  <li><a class="icon" target="_blank" rel="noopener" href="http://www.facebook.com/sharer.php?u=https://nowgnastack.github.io/2021/01/03/2021-01-03-TAVE_Research3/"><i class="fab fa-facebook " aria-hidden="true"></i></a></li>
  <li><a class="icon" target="_blank" rel="noopener" href="https://twitter.com/share?url=https://nowgnastack.github.io/2021/01/03/2021-01-03-TAVE_Research3/&text=Neural Network III"><i class="fab fa-twitter " aria-hidden="true"></i></a></li>
  <li><a class="icon" target="_blank" rel="noopener" href="http://www.linkedin.com/shareArticle?url=https://nowgnastack.github.io/2021/01/03/2021-01-03-TAVE_Research3/&title=Neural Network III"><i class="fab fa-linkedin " aria-hidden="true"></i></a></li>
  <li><a class="icon" target="_blank" rel="noopener" href="https://pinterest.com/pin/create/bookmarklet/?url=https://nowgnastack.github.io/2021/01/03/2021-01-03-TAVE_Research3/&is_video=false&description=Neural Network III"><i class="fab fa-pinterest " aria-hidden="true"></i></a></li>
  <li><a class="icon" href="mailto:?subject=Neural Network III&body=Check out this article: https://nowgnastack.github.io/2021/01/03/2021-01-03-TAVE_Research3/"><i class="fa-solid fa-envelope " aria-hidden="true"></i></a></li>
  <li><a class="icon" target="_blank" rel="noopener" href="https://getpocket.com/save?url=https://nowgnastack.github.io/2021/01/03/2021-01-03-TAVE_Research3/&title=Neural Network III"><i class="fab fa-get-pocket " aria-hidden="true"></i></a></li>
  <li><a class="icon" target="_blank" rel="noopener" href="http://reddit.com/submit?url=https://nowgnastack.github.io/2021/01/03/2021-01-03-TAVE_Research3/&title=Neural Network III"><i class="fab fa-reddit " aria-hidden="true"></i></a></li>
  <li><a class="icon" target="_blank" rel="noopener" href="http://www.stumbleupon.com/submit?url=https://nowgnastack.github.io/2021/01/03/2021-01-03-TAVE_Research3/&title=Neural Network III"><i class="fab fa-stumbleupon " aria-hidden="true"></i></a></li>
  <li><a class="icon" target="_blank" rel="noopener" href="http://digg.com/submit?url=https://nowgnastack.github.io/2021/01/03/2021-01-03-TAVE_Research3/&title=Neural Network III"><i class="fab fa-digg " aria-hidden="true"></i></a></li>
  <li><a class="icon" target="_blank" rel="noopener" href="http://www.tumblr.com/share/link?url=https://nowgnastack.github.io/2021/01/03/2021-01-03-TAVE_Research3/&name=Neural Network III&description="><i class="fab fa-tumblr " aria-hidden="true"></i></a></li>
  <li><a class="icon" target="_blank" rel="noopener" href="https://news.ycombinator.com/submitlink?u=https://nowgnastack.github.io/2021/01/03/2021-01-03-TAVE_Research3/&t=Neural Network III"><i class="fab fa-hacker-news " aria-hidden="true"></i></a></li>
</ul>

    </div>
    
    
      <div id="toc">
        <ol class="toc"><li class="toc-item toc-level-2"><a class="toc-link" href="#Loss-Function"><span class="toc-number">1.</span> <span class="toc-text">Loss Function</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#SSE-sum-of-squares-for-error"><span class="toc-number">1.1.</span> <span class="toc-text">SSE(sum of squares for error)</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Entropy"><span class="toc-number">2.</span> <span class="toc-text">Entropy</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#CEE-cross-entropy-error"><span class="toc-number">3.</span> <span class="toc-text">CEE(cross entropy error)</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#Cross-Entropy"><span class="toc-number">3.1.</span> <span class="toc-text">Cross Entropy</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#KL-Divergence-Kullback%E2%80%93Leibler-divergence"><span class="toc-number">4.</span> <span class="toc-text">KL Divergence(Kullback–Leibler divergence)</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%ED%95%99%EC%8A%B5-%EC%95%8C%EA%B3%A0%EB%A6%AC%EC%A6%98-%EA%B5%AC%ED%98%84"><span class="toc-number">5.</span> <span class="toc-text">학습 알고리즘 구현</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#two-layer-net-py"><span class="toc-number">6.</span> <span class="toc-text">two_layer_net.py</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#miniBatch-train-nNet-py"><span class="toc-number">6.1.</span> <span class="toc-text">miniBatch_train_nNet.py</span></a><ol class="toc-child"><li class="toc-item toc-level-6"><a class="toc-link" href="#References"><span class="toc-number">6.1.0.0.1.</span> <span class="toc-text">References</span></a></li></ol></li></ol></li></ol></li></ol></li></ol>
      </div>
    
  </span>
</div>

    
    <div class="content index py4 ">
        
        <article class="post h-entry" itemscope itemtype="http://schema.org/BlogPosting">
  <header>
    
    <h1 class="posttitle p-name" itemprop="name headline">
        Neural Network III
    </h1>



    <div class="meta">
      <span class="author p-author h-card" itemprop="author" itemscope itemtype="http://schema.org/Person">
        <span class="p-name" itemprop="name">nowgnas</span>
      </span>
      
    <div class="postdate">
      
        <time datetime="2021-01-02T15:00:00.000Z" class="dt-published" itemprop="datePublished">2021-01-03</time>
        
      
    </div>


      
<div class="article-category">
  <i class="fa-solid fa-archive"></i>
  <a class="category-link" href="/categories/deep-learning/">deep learning</a>
</div>


      
    <div class="article-tag">
        <i class="fa-solid fa-tag"></i>
        <a class="p-category" href="/tags/deep-learning/" rel="tag">deep learning</a>, <a class="p-category" href="/tags/tave/" rel="tag">tave</a>, <a class="p-category" href="/tags/tave-research/" rel="tag">tave research</a>
    </div>


    </div>
  </header>
  

  <div class="content e-content" itemprop="articleBody">
    <h2 id="Loss-Function"><a href="#Loss-Function" class="headerlink" title="Loss Function"></a>Loss Function</h2><ul>
<li>신경망에서는 하나의 지표를 기준으로 최적의 매개변수 값을 탐색한다. 신경망 학습에서 사용하는 지표는 손실 함수(loss function)이다.</li>
</ul>
<h3 id="SSE-sum-of-squares-for-error"><a href="#SSE-sum-of-squares-for-error" class="headerlink" title="SSE(sum of squares for error)"></a>SSE(sum of squares for error)</h3><p>\begin{align}<br>E &#x3D; {1&#x2F;2} {\sum}_k{(y_k - t_k)^2}<br>\end{align}</p>
<ul>
<li>$y_k$는 신경망이 추정한 값, $t_k$는 정답 레이블, $k$는 데이터 차원의 수를 나타낸다.</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">SSE</span>(<span class="params">y, t</span>):</span><br><span class="line">    <span class="keyword">return</span> <span class="number">0.5</span> * np.<span class="built_in">sum</span>((y - t) ** <span class="number">2</span>)</span><br></pre></td></tr></table></figure>

<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># t = 정답 레이블</span></span><br><span class="line">t = np.array([<span class="number">0</span>, <span class="number">0</span>, <span class="number">1</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>])</span><br><span class="line"></span><br><span class="line"><span class="comment"># y = softmax함수의 출력</span></span><br><span class="line">y = np.array([<span class="number">0.1</span>, <span class="number">0.05</span>, <span class="number">0.6</span>, <span class="number">0.0</span>, <span class="number">0.05</span>, <span class="number">0.1</span>, <span class="number">0.0</span>, <span class="number">0.1</span>, <span class="number">0.0</span>, <span class="number">0.0</span>])</span><br><span class="line"></span><br><span class="line"><span class="comment"># y2 = softmax함수의 출력</span></span><br><span class="line">y2 = np.array([<span class="number">0.1</span>, <span class="number">0.05</span>, <span class="number">0.1</span>, <span class="number">0.0</span>, <span class="number">0.05</span>, <span class="number">0.1</span>, <span class="number">0.6</span>, <span class="number">0.3</span>, <span class="number">0.0</span>, <span class="number">0.0</span>])</span><br><span class="line"></span><br><span class="line">SSE(y, t)  <span class="comment"># 0.09750000000000003</span></span><br><span class="line">SSE(y2, t) <span class="comment"># 0.6425</span></span><br></pre></td></tr></table></figure>

<ul>
<li>정답은 ‘2’인 배열 안에서 SSE의 기준으로 첫 번째 추정 결과가 오차가 더 작기 때문에 정답에 가깝다고 판단 할 수 있다.</li>
</ul>
<h2 id="Entropy"><a href="#Entropy" class="headerlink" title="Entropy"></a>Entropy</h2><ul>
<li><p>엔트로피는 정보를 표현하는데 필요한 최소 평균 자원량이다.</p>
</li>
<li><p>자원량은 0 또는 1의 bits로 표현 한다.</p>
</li>
<li><p>인코딩시 확률이 낮은 것들은 길게 코딩하고 높은 것들은 짧게 코딩한다.</p>
<p><img src="/images/img/posts/TaveResearch/neuralN3/log.png" alt="log.png"></p>
</li>
<li><p>y축은 코딩되는 길이, x축은 확률이다.</p>
</li>
<li><p>아래 식은 확률에 따른 길이를 나타낸다.</p>
</li>
</ul>
<p>\begin{align}<br>-\log_2{P_i}<br>\end{align}</p>
<ul>
<li>자원량의 최소 기댓값이 최소 평균 길이다.</li>
</ul>
<p>\begin{align}<br>E &#x3D; {\sum}_i {p_i (-\log_2 P_i)}<br>\end{align}</p>
<h2 id="CEE-cross-entropy-error"><a href="#CEE-cross-entropy-error" class="headerlink" title="CEE(cross entropy error)"></a>CEE(cross entropy error)</h2><h3 id="Cross-Entropy"><a href="#Cross-Entropy" class="headerlink" title="Cross Entropy"></a>Cross Entropy</h3><ul>
<li>교차 엔트로피는 추정한 기댓값이다</li>
</ul>
<p>\begin{align}<br>E &#x3D; {\sum}_i{p_i(-log_2 Q_i)}<br>\end{align}</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">CEE</span>(<span class="params">y, t</span>):</span><br><span class="line">    delta = <span class="number">1e-7</span></span><br><span class="line">    <span class="keyword">return</span> -np.<span class="built_in">sum</span>(t * np.log(y + delta))</span><br></pre></td></tr></table></figure>

<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># t = 정답 레이블</span></span><br><span class="line">t = np.array([<span class="number">0</span>, <span class="number">0</span>, <span class="number">1</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>])</span><br><span class="line"></span><br><span class="line"><span class="comment"># y = softmax함수의 출력</span></span><br><span class="line">y = np.array([<span class="number">0.1</span>, <span class="number">0.05</span>, <span class="number">0.6</span>, <span class="number">0.0</span>, <span class="number">0.05</span>, <span class="number">0.1</span>, <span class="number">0.0</span>, <span class="number">0.1</span>, <span class="number">0.0</span>, <span class="number">0.0</span>])</span><br><span class="line"></span><br><span class="line"><span class="comment"># y2 = softmax함수의 출력</span></span><br><span class="line">y2 = np.array([<span class="number">0.1</span>, <span class="number">0.05</span>, <span class="number">0.1</span>, <span class="number">0.0</span>, <span class="number">0.05</span>, <span class="number">0.1</span>, <span class="number">0.6</span>, <span class="number">0.3</span>, <span class="number">0.0</span>, <span class="number">0.0</span>])</span><br><span class="line"></span><br><span class="line">CEE(y, t)  <span class="comment"># 0.510825457099338</span></span><br><span class="line">CEE(y2, t) <span class="comment"># 2.302584092994546</span></span><br></pre></td></tr></table></figure>

<ul>
<li>오차 제곱합의 예시와 같이 정답은 ‘2’이다.</li>
<li>delta는 np.log를 계산할 대 0이 입력되면 마이너스 무한대(-inf)가 되는 것을 방지하기 위해 아주 작은 수를 사용하였다.</li>
<li>오차값이 더 작은 첫 번째 추정이 정답이다.</li>
</ul>
<h2 id="KL-Divergence-Kullback–Leibler-divergence"><a href="#KL-Divergence-Kullback–Leibler-divergence" class="headerlink" title="KL Divergence(Kullback–Leibler divergence)"></a>KL Divergence(Kullback–Leibler divergence)</h2><p>\begin{align}<br>KL(p||q) &#x3D; -{\sum}_i {p_i \log({q_i &#x2F; p_i})}<br>\end{align}</p>
<ul>
<li>KL divergence는 p와 q의 cross-entropy에서 p의 entropy를 뺀 값이다.</li>
<li>cross entropy를 minimize 하는 것은 KL divergence를 minimize하는것과 같다. (p의 entropy는 고정된 값이기 때문)<blockquote>
<p><a target="_blank" rel="noopener" href="https://hyunw.kim/blog/2017/10/27/KL_divergence.html">초보를 위한 정보이론 안내서 - KL divergence 쉽게 보기</a></p>
</blockquote>
</li>
</ul>
<h2 id="학습-알고리즘-구현"><a href="#학습-알고리즘-구현" class="headerlink" title="학습 알고리즘 구현"></a>학습 알고리즘 구현</h2><ul>
<li>2층 신경망을 구현해 본다.</li>
</ul>
<ol>
<li><p>미니 배치</p>
<p>훈련 데이터 중 일부를 무작위로 가져온다. 가져온 미니배치의 손실 함수 값을 줄이는것이 목표이다.</p>
</li>
<li><p>기울기 산출</p>
<p>미니배치의 손실 함수 값을 줄이기 위해 각 가중치 매개변수의 기울기를 구한다. 기울기는 손실 함수의 값을 가장 작게 하는 방향을 제시한다.</p>
</li>
<li><p>매개변수 갱신</p>
<p>가중치 매개변수를 기울기 방향으로 조금씩 갱신한다.</p>
</li>
<li><p>1~3을 반복한다.</p>
</li>
</ol>
<h2 id="two-layer-net-py"><a href="#two-layer-net-py" class="headerlink" title="two_layer_net.py"></a>two_layer_net.py</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> sys, os</span><br><span class="line"></span><br><span class="line">sys.path.append(os.pardir)  <span class="comment"># 부모 디렉터리의 파일을 가져올 수 있도록 설정</span></span><br><span class="line"><span class="keyword">from</span> common.functions <span class="keyword">import</span> *</span><br><span class="line"><span class="keyword">from</span> common.gradient <span class="keyword">import</span> numerical_gradient</span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">TwoLayerNet</span>:</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, input_size, hidden_size, output_size, weight_init_std=<span class="number">0.01</span></span>):</span><br><span class="line">        <span class="comment"># 가중치 초기화</span></span><br><span class="line">        self.params = &#123;&#125;</span><br><span class="line">        self.params[<span class="string">&#x27;W1&#x27;</span>] = weight_init_std * np.random.randn(input_size, hidden_size)</span><br><span class="line">        self.params[<span class="string">&#x27;b1&#x27;</span>] = np.zeros(hidden_size)</span><br><span class="line">        self.params[<span class="string">&#x27;W2&#x27;</span>] = weight_init_std * np.random.randn(hidden_size, output_size)</span><br><span class="line">        self.params[<span class="string">&#x27;b2&#x27;</span>] = np.zeros(output_size)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">predict</span>(<span class="params">self, x</span>):</span><br><span class="line">        W1, W2 = self.params[<span class="string">&#x27;W1&#x27;</span>], self.params[<span class="string">&#x27;W2&#x27;</span>]</span><br><span class="line">        b1, b2 = self.params[<span class="string">&#x27;b1&#x27;</span>], self.params[<span class="string">&#x27;b2&#x27;</span>]</span><br><span class="line"></span><br><span class="line">        a1 = np.dot(x, W1) + b1</span><br><span class="line">        z1 = sigmoid(a1)</span><br><span class="line">        a2 = np.dot(z1, W2) + b2</span><br><span class="line">        y = softmax(a2)</span><br><span class="line"></span><br><span class="line">        <span class="keyword">return</span> y</span><br><span class="line"></span><br><span class="line">    <span class="comment"># x : 입력 데이터, t : 정답 레이블</span></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">loss</span>(<span class="params">self, x, t</span>):</span><br><span class="line">        y = self.predict(x)</span><br><span class="line"></span><br><span class="line">        <span class="keyword">return</span> cross_entropy_error(y, t)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">accuracy</span>(<span class="params">self, x, t</span>):</span><br><span class="line">        y = self.predict(x)</span><br><span class="line">        y = np.argmax(y, axis=<span class="number">1</span>)</span><br><span class="line">        t = np.argmax(t, axis=<span class="number">1</span>)</span><br><span class="line"></span><br><span class="line">        accuracy = np.<span class="built_in">sum</span>(y == t) / <span class="built_in">float</span>(x.shape[<span class="number">0</span>])</span><br><span class="line">        <span class="keyword">return</span> accuracy</span><br><span class="line"></span><br><span class="line">    <span class="comment"># x : 입력 데이터, t : 정답 레이블</span></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">gradient</span>(<span class="params">self, x, t</span>):</span><br><span class="line">        W1, W2 = self.params[<span class="string">&#x27;W1&#x27;</span>], self.params[<span class="string">&#x27;W2&#x27;</span>]</span><br><span class="line">        b1, b2 = self.params[<span class="string">&#x27;b1&#x27;</span>], self.params[<span class="string">&#x27;b2&#x27;</span>]</span><br><span class="line">        grads = &#123;&#125;</span><br><span class="line"></span><br><span class="line">        batch_num = x.shape[<span class="number">0</span>]</span><br><span class="line"></span><br><span class="line">        <span class="comment"># forward</span></span><br><span class="line">        a1 = np.dot(x, W1) + b1</span><br><span class="line">        z1 = sigmoid(a1)</span><br><span class="line">        a2 = np.dot(z1, W2) + b2</span><br><span class="line">        y = softmax(a2)</span><br><span class="line"></span><br><span class="line">        <span class="comment"># backward</span></span><br><span class="line">        dy = (y - t) / batch_num</span><br><span class="line">        grads[<span class="string">&#x27;W2&#x27;</span>] = np.dot(z1.T, dy)</span><br><span class="line">        grads[<span class="string">&#x27;b2&#x27;</span>] = np.<span class="built_in">sum</span>(dy, axis=<span class="number">0</span>)</span><br><span class="line"></span><br><span class="line">        da1 = np.dot(dy, W2.T)</span><br><span class="line">        dz1 = sigmoid_grad(a1) * da1</span><br><span class="line">        grads[<span class="string">&#x27;W1&#x27;</span>] = np.dot(x.T, dz1)</span><br><span class="line">        grads[<span class="string">&#x27;b1&#x27;</span>] = np.<span class="built_in">sum</span>(dz1, axis=<span class="number">0</span>)</span><br><span class="line"></span><br><span class="line">        <span class="keyword">return</span> grads</span><br></pre></td></tr></table></figure>

<ul>
<li>__init__에서는 입력층과 은닉층의 뉴런 수, 출력층의 뉴런 수 예측을 인수로 받는다.</li>
<li>predict함수는 예측을 수행한다. 파라미터 x는 이미지 데이터이다.</li>
<li>accuracy함수는 정확도를 구한다.</li>
<li>gradient함수는 가중치 매개변수의 기울기를 구한다. 오차 역전파(backward)를 사용하여 수치 미분을 사용하는것 보다 시간이 단축된다.</li>
</ul>
<h3 id="miniBatch-train-nNet-py"><a href="#miniBatch-train-nNet-py" class="headerlink" title="miniBatch_train_nNet.py"></a>miniBatch_train_nNet.py</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> sys, os</span><br><span class="line"></span><br><span class="line"><span class="comment"># 부모 디렉터리의 파일을 가져올 수 있도록 설정</span></span><br><span class="line">sys.path.append(os.pardir)</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"><span class="keyword">from</span> dataset.mnist <span class="keyword">import</span> load_mnist</span><br><span class="line"><span class="keyword">from</span> two_layer_net <span class="keyword">import</span> TwoLayerNet</span><br><span class="line"></span><br><span class="line"><span class="comment"># 데이터 읽기</span></span><br><span class="line">(x_train, t_train), (x_test, t_test) = load_mnist(normalize=<span class="literal">True</span>, one_hot_label=<span class="literal">True</span>)</span><br><span class="line"></span><br><span class="line">network = TwoLayerNet(input_size=<span class="number">784</span>, hidden_size=<span class="number">50</span>, output_size=<span class="number">10</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 하이퍼파라미터</span></span><br><span class="line">iters_num = <span class="number">10000</span>  <span class="comment"># 반복 횟수를 적절히 설정한다.</span></span><br><span class="line">train_size = x_train.shape[<span class="number">0</span>]</span><br><span class="line">batch_size = <span class="number">100</span>  <span class="comment"># 미니배치 크기</span></span><br><span class="line">learning_rate = <span class="number">0.1</span></span><br><span class="line"></span><br><span class="line">train_loss_list = []</span><br><span class="line">train_acc_list = []</span><br><span class="line">test_acc_list = []</span><br><span class="line"></span><br><span class="line"><span class="comment"># 1에폭당 반복 수</span></span><br><span class="line">iter_per_epoch = <span class="built_in">max</span>(train_size / batch_size, <span class="number">1</span>)</span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(iters_num):</span><br><span class="line">    <span class="comment"># 미니배치 획득</span></span><br><span class="line">    batch_mask = np.random.choice(train_size, batch_size)</span><br><span class="line">    x_batch = x_train[batch_mask]</span><br><span class="line">    t_batch = t_train[batch_mask]</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 기울기 계산</span></span><br><span class="line">    <span class="comment"># grad = network.numerical_gradient(x_batch, t_batch)</span></span><br><span class="line">    grad = network.gradient(x_batch, t_batch)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 매개변수 갱신</span></span><br><span class="line">    <span class="keyword">for</span> key <span class="keyword">in</span> (<span class="string">&#x27;W1&#x27;</span>, <span class="string">&#x27;b1&#x27;</span>, <span class="string">&#x27;W2&#x27;</span>, <span class="string">&#x27;b2&#x27;</span>):</span><br><span class="line">        network.params[key] -= learning_rate * grad[key]</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 학습 경과 기록</span></span><br><span class="line">    loss = network.loss(x_batch, t_batch)</span><br><span class="line">    train_loss_list.append(loss)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 1에폭당 정확도 계산</span></span><br><span class="line">    <span class="keyword">if</span> i % iter_per_epoch == <span class="number">0</span>:</span><br><span class="line">        train_acc = network.accuracy(x_train, t_train)</span><br><span class="line">        test_acc = network.accuracy(x_test, t_test)</span><br><span class="line">        train_acc_list.append(train_acc)</span><br><span class="line">        test_acc_list.append(test_acc)</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">&quot;train acc, test acc | &quot;</span> + <span class="built_in">str</span>(train_acc) + <span class="string">&quot;, &quot;</span> + <span class="built_in">str</span>(test_acc))</span><br></pre></td></tr></table></figure>

<p><img src="/images/img/posts/TaveResearch/neuralN3/loss_acc.png" alt="loss_acc.png"></p>
<ul>
<li>미니배치 크기를 100으로 하여 한번의 iteration을 수행할 때마다 임의로 100개의 데이터를 추린다.</li>
<li>100개의 미니배치를 대상으로 확률적 경사 하강법을 수행하여 매개변수를 갱신한다.</li>
<li>갱신할 때마다 훈련 데이터에 대한 손실 함수를 계산한다.</li>
<li>왼쪽 그래프는 각 iteration마다의 loss를 나타낸 것이고 오른쪽 그래프는 epch마다 훈련 데이터와 시험 데이터에 대한 정확도를 나타냈다.</li>
<li>훈련 데이터와 시험 데이터가 차이가 거의 없는것을 볼 수 있다.</li>
</ul>
<h6 id="References"><a href="#References" class="headerlink" title="References"></a>References</h6><blockquote>
<p><sub>코드: <a target="_blank" rel="noopener" href="https://www.hanbit.co.kr/store/books/look.php?p_code=B8475831198">밑바닥부터 시작하는 딥러닝</a></sub><br><sub>YouTube: <a target="_blank" rel="noopener" href="https://www.youtube.com/channel/UCcbPAIfCa4q0x7x8yFXmBag">혁펜하임</a></sub></p>
</blockquote>

  </div>
</article>


    <div class="blog-post-comments">
        <div id="utterances_thread">
            <noscript>Please enable JavaScript to view the comments.</noscript>
        </div>
    </div>


        
          <div id="footer-post-container">
  <div id="footer-post">

    <div id="nav-footer" style="display: none">
      <ul>
        
          <li><a href="/">Home</a></li>
        
          <li><a href="/about/">About</a></li>
        
          <li><a href="/archives/">Writing</a></li>
        
          <li><a target="_blank" rel="noopener" href="https://github.com/nowgnas">Projects</a></li>
        
      </ul>
    </div>

    
    
      <div id="toc-footer" style="display: none">
        <ol class="toc"><li class="toc-item toc-level-2"><a class="toc-link" href="#Loss-Function"><span class="toc-number">1.</span> <span class="toc-text">Loss Function</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#SSE-sum-of-squares-for-error"><span class="toc-number">1.1.</span> <span class="toc-text">SSE(sum of squares for error)</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Entropy"><span class="toc-number">2.</span> <span class="toc-text">Entropy</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#CEE-cross-entropy-error"><span class="toc-number">3.</span> <span class="toc-text">CEE(cross entropy error)</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#Cross-Entropy"><span class="toc-number">3.1.</span> <span class="toc-text">Cross Entropy</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#KL-Divergence-Kullback%E2%80%93Leibler-divergence"><span class="toc-number">4.</span> <span class="toc-text">KL Divergence(Kullback–Leibler divergence)</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%ED%95%99%EC%8A%B5-%EC%95%8C%EA%B3%A0%EB%A6%AC%EC%A6%98-%EA%B5%AC%ED%98%84"><span class="toc-number">5.</span> <span class="toc-text">학습 알고리즘 구현</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#two-layer-net-py"><span class="toc-number">6.</span> <span class="toc-text">two_layer_net.py</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#miniBatch-train-nNet-py"><span class="toc-number">6.1.</span> <span class="toc-text">miniBatch_train_nNet.py</span></a><ol class="toc-child"><li class="toc-item toc-level-6"><a class="toc-link" href="#References"><span class="toc-number">6.1.0.0.1.</span> <span class="toc-text">References</span></a></li></ol></li></ol></li></ol></li></ol></li></ol>
      </div>
    

    <div id="share-footer" style="display: none">
      <ul>
  <li><a class="icon" target="_blank" rel="noopener" href="http://www.facebook.com/sharer.php?u=https://nowgnastack.github.io/2021/01/03/2021-01-03-TAVE_Research3/"><i class="fab fa-facebook fa-lg" aria-hidden="true"></i></a></li>
  <li><a class="icon" target="_blank" rel="noopener" href="https://twitter.com/share?url=https://nowgnastack.github.io/2021/01/03/2021-01-03-TAVE_Research3/&text=Neural Network III"><i class="fab fa-twitter fa-lg" aria-hidden="true"></i></a></li>
  <li><a class="icon" target="_blank" rel="noopener" href="http://www.linkedin.com/shareArticle?url=https://nowgnastack.github.io/2021/01/03/2021-01-03-TAVE_Research3/&title=Neural Network III"><i class="fab fa-linkedin fa-lg" aria-hidden="true"></i></a></li>
  <li><a class="icon" target="_blank" rel="noopener" href="https://pinterest.com/pin/create/bookmarklet/?url=https://nowgnastack.github.io/2021/01/03/2021-01-03-TAVE_Research3/&is_video=false&description=Neural Network III"><i class="fab fa-pinterest fa-lg" aria-hidden="true"></i></a></li>
  <li><a class="icon" href="mailto:?subject=Neural Network III&body=Check out this article: https://nowgnastack.github.io/2021/01/03/2021-01-03-TAVE_Research3/"><i class="fa-solid fa-envelope fa-lg" aria-hidden="true"></i></a></li>
  <li><a class="icon" target="_blank" rel="noopener" href="https://getpocket.com/save?url=https://nowgnastack.github.io/2021/01/03/2021-01-03-TAVE_Research3/&title=Neural Network III"><i class="fab fa-get-pocket fa-lg" aria-hidden="true"></i></a></li>
  <li><a class="icon" target="_blank" rel="noopener" href="http://reddit.com/submit?url=https://nowgnastack.github.io/2021/01/03/2021-01-03-TAVE_Research3/&title=Neural Network III"><i class="fab fa-reddit fa-lg" aria-hidden="true"></i></a></li>
  <li><a class="icon" target="_blank" rel="noopener" href="http://www.stumbleupon.com/submit?url=https://nowgnastack.github.io/2021/01/03/2021-01-03-TAVE_Research3/&title=Neural Network III"><i class="fab fa-stumbleupon fa-lg" aria-hidden="true"></i></a></li>
  <li><a class="icon" target="_blank" rel="noopener" href="http://digg.com/submit?url=https://nowgnastack.github.io/2021/01/03/2021-01-03-TAVE_Research3/&title=Neural Network III"><i class="fab fa-digg fa-lg" aria-hidden="true"></i></a></li>
  <li><a class="icon" target="_blank" rel="noopener" href="http://www.tumblr.com/share/link?url=https://nowgnastack.github.io/2021/01/03/2021-01-03-TAVE_Research3/&name=Neural Network III&description="><i class="fab fa-tumblr fa-lg" aria-hidden="true"></i></a></li>
  <li><a class="icon" target="_blank" rel="noopener" href="https://news.ycombinator.com/submitlink?u=https://nowgnastack.github.io/2021/01/03/2021-01-03-TAVE_Research3/&t=Neural Network III"><i class="fab fa-hacker-news fa-lg" aria-hidden="true"></i></a></li>
</ul>

    </div>

    <div id="actions-footer">
        <a id="menu" class="icon" href="#" onclick="$('#nav-footer').toggle();return false;"><i class="fa-solid fa-bars fa-lg" aria-hidden="true"></i> Menu</a>
        
          <a id="toc" class="icon" href="#" onclick="$('#toc-footer').toggle();return false;"><i class="fa-solid fa-list fa-lg" aria-hidden="true"></i> TOC</a>
        
        <a id="share" class="icon" href="#" onclick="$('#share-footer').toggle();return false;"><i class="fa-solid fa-share-alt fa-lg" aria-hidden="true"></i> Share</a>
        <a id="top" style="display:none" class="icon" href="#" onclick="$('html, body').animate({ scrollTop: 0 }, 'fast');"><i class="fa-solid fa-chevron-up fa-lg" aria-hidden="true"></i> Top</a>
    </div>

  </div>
</div>

        
        <footer id="footer">
  <div class="footer-left">
    Copyright &copy;
    
    
    2020-2023
    nowgnas
  </div>
  <div class="footer-right">
    <nav>
      <ul>
        <!--
       --><li><a href="/">Home</a></li><!--
     --><!--
       --><li><a href="/about/">About</a></li><!--
     --><!--
       --><li><a href="/archives/">Writing</a></li><!--
     --><!--
       --><li><a target="_blank" rel="noopener" href="https://github.com/nowgnas">Projects</a></li><!--
     -->
      </ul>
    </nav>
  </div>
</footer>

    </div>
    <!-- styles -->



  <link rel="preload" as="style" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.4.0/css/all.min.css" crossorigin="anonymous" onload="this.onload=null;this.rel='stylesheet'"/>


    <!-- jquery -->

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.6.0/jquery.min.js" crossorigin="anonymous"></script>




<!-- clipboard -->

  
    <script src="https://cdnjs.cloudflare.com/ajax/libs/clipboard.js/2.0.7/clipboard.min.js" crossorigin="anonymous"></script>
  
  <script type="text/javascript">
  $(function() {
    // copy-btn HTML
    var btn = "<span class=\"btn-copy tooltipped tooltipped-sw\" aria-label=\"Copy to clipboard!\">";
    btn += '<i class="fa-regular fa-clone"></i>';
    btn += '</span>';
    // mount it!
    $(".highlight table").before(btn);
    var clip = new ClipboardJS('.btn-copy', {
      text: function(trigger) {
        return Array.from(trigger.nextElementSibling.querySelectorAll('.code')).reduce((str,it)=>str+it.innerText+'\n','')
      }
    });
    clip.on('success', function(e) {
      e.trigger.setAttribute('aria-label', "Copied!");
      e.clearSelection();
    })
  })
  </script>


<script src="/js/main.js"></script>

<!-- search -->

<!-- Baidu Analytics -->

<!-- Cloudflare Analytics -->

<!-- Disqus Comments -->

<!-- utterances Comments -->

    <script type="text/javascript">
      var utterances_repo = 'nowgnastack/nowgnastack.github.io';
      var utterances_issue_term = 'pathname';
      var utterances_label = 'Comment';
      var utterances_theme = 'github-light';

      (function(){
          var script = document.createElement('script');

          script.src = 'https://utteranc.es/client.js';
          script.setAttribute('repo', utterances_repo);
          script.setAttribute('issue-term', 'pathname');
          script.setAttribute('label', utterances_label);
          script.setAttribute('theme', utterances_theme);
          script.setAttribute('crossorigin', 'anonymous');
          script.async = true;
          (document.getElementById('utterances_thread')).appendChild(script);
      }());
  </script>

</body>
</html>
